{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3cfdcf60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ta.trend import EMAIndicator, macd, PSARIndicator\n",
    "from ta.volatility import BollingerBands\n",
    "from ta.momentum import rsi\n",
    "\n",
    "def AddIndicators(df):\n",
    "    df[\"ema5\"] = EMAIndicator(close=df[\"close\"], window=5, fillna=True).ema_indicator()\n",
    "    df[\"ema8\"] = EMAIndicator(close=df[\"close\"], window=8, fillna=True).ema_indicator()\n",
    "    df[\"ema13\"] = EMAIndicator(close=df[\"close\"], window=13, fillna=True).ema_indicator()\n",
    "\n",
    "    df[\"MACD\"] = macd(close=df[\"close\"], window_slow=26, window_fast=12, fillna=True)\n",
    "\n",
    "    df[\"RSI\"] = rsi(close=df[\"close\"], window=14, fillna=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a0b03ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "from mplfinance.original_flavor import candlestick_ohlc\n",
    "import matplotlib.dates as mpl_dates\n",
    "from datetime import datetime\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def Write_to_file(Date, net_worth, filename='{}.txt'.format(datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))):\n",
    "    for i in net_worth: \n",
    "        Date += \" {}\".format(i)\n",
    "\n",
    "    if not os.path.exists('logs'):\n",
    "        os.makedirs('logs')\n",
    "    file = open(\"logs/\"+filename, 'a+')\n",
    "    file.write(Date+\"\\n\")\n",
    "    file.close()\n",
    "\n",
    "class TradingGraph:\n",
    "    \n",
    "    def __init__(self, Render_range, Show_reward=False, Show_indicators=False):\n",
    "        self.Volume = deque(maxlen=Render_range)\n",
    "        self.net_worth = deque(maxlen=Render_range)\n",
    "        self.render_data = deque(maxlen=Render_range)\n",
    "        self.Render_range = Render_range\n",
    "        self.Show_reward = Show_reward\n",
    "        self.Show_indicators = Show_indicators\n",
    "\n",
    "        plt.style.use('ggplot')\n",
    "        plt.close('all')\n",
    "        self.fig = plt.figure(figsize=(16,8)) \n",
    "\n",
    "        self.ax1 = plt.subplot2grid((6,1), (0,0), rowspan=5, colspan=1)\n",
    "        \n",
    "        self.ax2 = plt.subplot2grid((6,1), (5,0), rowspan=1, colspan=1, sharex=self.ax1)\n",
    "        \n",
    "        self.ax3 = self.ax1.twinx()\n",
    "\n",
    "        self.date_format = mpl_dates.DateFormatter('%d-%m-%Y')\n",
    "\n",
    "        plt.subplots_adjust(left=0.07, bottom=-0.1, right=0.93, top=0.97, wspace=0, hspace=0)\n",
    "\n",
    "        if self.Show_indicators:\n",
    "            self.Create_indicators_lists()\n",
    "\n",
    "    def Create_indicators_lists(self):\n",
    "        self.ax4 = self.ax2.twinx()\n",
    "        self.ema5 = deque(maxlen=self.Render_range)\n",
    "        self.ema8 = deque(maxlen=self.Render_range)\n",
    "        self.ema13 = deque(maxlen=self.Render_range)\n",
    "        self.MACD = deque(maxlen=self.Render_range)\n",
    "        self.RSI = deque(maxlen=self.Render_range)\n",
    "\n",
    "\n",
    "    def Plot_indicators(self, df, Date_Render_range):\n",
    "        self.ema5.append(df[\"ema5\"])\n",
    "        self.ema8.append(df[\"ema8\"])\n",
    "        self.ema13.append(df[\"ema13\"])\n",
    "\n",
    "        self.MACD.append(df[\"MACD\"]*100)\n",
    "        self.RSI.append(df[\"RSI\"])\n",
    "\n",
    "        self.ax4.clear()\n",
    "        self.ax4.plot(Date_Render_range, self.MACD,'r-')\n",
    "\n",
    "        self.ax4.plot(Date_Render_range, self.RSI,'g-')\n",
    "\n",
    "    def render(self, df, net_worth, trades):\n",
    "        Date = df[\"datetime\"]\n",
    "        Open = df[\"open\"]\n",
    "        High = df[\"high\"]\n",
    "        Low = df[\"low\"]\n",
    "        Close = df[\"close\"]\n",
    "        Volume = df[\"volume\"]\n",
    "        self.Volume.append(Volume)\n",
    "        self.net_worth.append(net_worth)\n",
    "\n",
    "        Date = mpl_dates.date2num([pd.to_datetime(Date)])[0]\n",
    "        self.render_data.append([Date, Open, High, Low, Close])\n",
    "        \n",
    "        self.ax1.clear()\n",
    "        candlestick_ohlc(self.ax1, self.render_data, width=0.8/24, colorup='green', colordown='red', alpha=0.8)\n",
    "\n",
    "        Date_Render_range = [i[0] for i in self.render_data]\n",
    "        self.ax2.clear()\n",
    "        self.ax2.fill_between(Date_Render_range, self.Volume, 0)\n",
    "\n",
    "        if self.Show_indicators:\n",
    "            self.Plot_indicators(df, Date_Render_range)\n",
    "\n",
    "        self.ax3.clear()\n",
    "        self.ax3.plot(Date_Render_range, self.net_worth, color=\"blue\")\n",
    "        \n",
    "        self.ax1.xaxis.set_major_formatter(self.date_format)\n",
    "        self.fig.autofmt_xdate()\n",
    "\n",
    "        minimum = np.min(np.array(self.render_data)[:,1:])\n",
    "        maximum = np.max(np.array(self.render_data)[:,1:])\n",
    "        RANGE = maximum - minimum\n",
    "\n",
    "        for trade in trades:\n",
    "            trade_date = mpl_dates.date2num([pd.to_datetime(trade['datetime'])])[0]\n",
    "            if trade_date in Date_Render_range:\n",
    "                if trade['type'] == 'buy':\n",
    "                    high_low = trade['low'] - RANGE*0.02\n",
    "                    ycoords = trade['low'] - RANGE*0.08\n",
    "                    self.ax1.scatter(trade_date, high_low, c='green', label='green', s = 120, edgecolors='none', marker=\"^\")\n",
    "                else:\n",
    "                    high_low = trade['high'] + RANGE*0.02\n",
    "                    ycoords = trade['high'] + RANGE*0.06\n",
    "                    self.ax1.scatter(trade_date, high_low, c='red', label='red', s = 120, edgecolors='none', marker=\"v\")\n",
    "\n",
    "                if self.Show_reward:\n",
    "                    try:\n",
    "                        self.ax1.annotate('{0:.2f}'.format(trade['Reward']), (trade_date-0.02, high_low), xytext=(trade_date-0.02, ycoords),\n",
    "                                                   bbox=dict(boxstyle='round', fc='w', ec='k', lw=1), fontsize=\"small\")\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "        self.ax2.set_xlabel('Date')\n",
    "        self.ax1.set_ylabel('Price')\n",
    "        self.ax3.set_ylabel('Balance')\n",
    "\n",
    "        self.fig.tight_layout()\n",
    "\n",
    "        self.fig.canvas.draw()\n",
    "        \n",
    "        img = np.fromstring(self.fig.canvas.tostring_rgb(), dtype=np.uint8, sep='')\n",
    "        img  = img.reshape(self.fig.canvas.get_width_height()[::-1] + (3,))\n",
    "        \n",
    "        image = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        cv2.imshow(\"trading bot\",image)\n",
    "\n",
    "        if cv2.waitKey(25) & 0xFF == ord(\"q\"):\n",
    "            cv2.destroyAllWindows()\n",
    "            return\n",
    "        else:\n",
    "            return img\n",
    "        \n",
    "\n",
    "def Plot_OHCL(df):\n",
    "    df_original = df.copy()\n",
    "    df[\"datetime\"] = pd.to_datetime(df.Date)\n",
    "    df[\"datetime\"] = df[\"datetime\"].apply(mpl_dates.date2num)\n",
    "\n",
    "    df = df[['datetime', 'open', 'high', 'low', 'close', 'volume']]\n",
    "    \n",
    "    plt.style.use('ggplot')\n",
    "    \n",
    "    fig = plt.figure(figsize=(16,8)) \n",
    "\n",
    "    ax1 = plt.subplot2grid((6,1), (0,0), rowspan=5, colspan=1)\n",
    "\n",
    "    ax2 = plt.subplot2grid((6,1), (5,0), rowspan=1, colspan=1, sharex=ax1)\n",
    "\n",
    "    candlestick_ohlc(ax1, df.values, width=0.8/24, colorup='green', colordown='red', alpha=0.8)\n",
    "    ax1.set_ylabel('Price', fontsize=12)\n",
    "    plt.xlabel('Date')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    ax1.plot(df[\"datetime\"], df_original['ema5'],'-')\n",
    "    ax1.plot(df[\"datetime\"], df_original['ema8'],'-')\n",
    "    ax1.plot(df[\"datetime\"], df_original['ema13'],'-')\n",
    "\n",
    "    ax2.plot(df[\"datetime\"], df_original['MACD']*100,'-')\n",
    "\n",
    "    ax2.plot(df[\"datetime\"], df_original['RSI'],'-')\n",
    "\n",
    "    ax1.xaxis.set_major_formatter(mpl_dates.DateFormatter('%y-%m-%d'))\n",
    "    fig.autofmt_xdate()\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "be09166f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Conv1D, MaxPooling1D, LSTM\n",
    "from tensorflow.keras import backend as K\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if len(gpus) > 0:\n",
    "    print(f'GPUs {gpus}')\n",
    "    try: tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    except RuntimeError: pass\n",
    "\n",
    "class Actor_Model:\n",
    "    def __init__(self, input_shape, action_space, lr, optimizer):\n",
    "        X_input = Input(input_shape)\n",
    "        self.action_space = action_space\n",
    "\n",
    "        X = Flatten(input_shape=input_shape)(X_input)\n",
    "        X = Dense(512, activation=\"relu\")(X)\n",
    "        X = Dense(256, activation=\"relu\")(X)\n",
    "        X = Dense(64, activation=\"relu\")(X)\n",
    "        output = Dense(self.action_space, activation=\"softmax\")(X)\n",
    "\n",
    "        self.Actor = Model(inputs = X_input, outputs = output)\n",
    "        self.Actor.compile(loss=self.ppo_loss, optimizer=optimizer(lr=lr))\n",
    "\n",
    "    def ppo_loss(self, y_true, y_pred):\n",
    "        advantages, prediction_picks, actions = y_true[:, :1], y_true[:, 1:1+self.action_space], y_true[:, 1+self.action_space:]\n",
    "        LOSS_CLIPPING = 0.2\n",
    "        ENTROPY_LOSS = 0.001\n",
    "        \n",
    "        prob = actions * y_pred\n",
    "        old_prob = actions * prediction_picks\n",
    "\n",
    "        prob = K.clip(prob, 1e-10, 1.0)\n",
    "        old_prob = K.clip(old_prob, 1e-10, 1.0)\n",
    "\n",
    "        ratio = K.exp(K.log(prob) - K.log(old_prob))\n",
    "        \n",
    "        p1 = ratio * advantages\n",
    "        p2 = K.clip(ratio, min_value=1 - LOSS_CLIPPING, max_value=1 + LOSS_CLIPPING) * advantages\n",
    "\n",
    "        actor_loss = -K.mean(K.minimum(p1, p2))\n",
    "\n",
    "        entropy = -(y_pred * K.log(y_pred + 1e-10))\n",
    "        entropy = ENTROPY_LOSS * K.mean(entropy)\n",
    "        \n",
    "        total_loss = actor_loss - entropy\n",
    "\n",
    "        return total_loss\n",
    "\n",
    "    def actor_predict(self, state):\n",
    "        return self.Actor.predict(state)\n",
    "\n",
    "class Critic_Model:\n",
    "    def __init__(self, input_shape, action_space, lr, optimizer):\n",
    "        X_input = Input(input_shape)\n",
    "\n",
    "        V = Flatten(input_shape=input_shape)(X_input)\n",
    "        V = Dense(512, activation=\"relu\")(V)\n",
    "        V = Dense(256, activation=\"relu\")(V)\n",
    "        V = Dense(64, activation=\"relu\")(V)\n",
    "        value = Dense(1, activation=None)(V)\n",
    "\n",
    "        self.Critic = Model(inputs=X_input, outputs = value)\n",
    "        self.Critic.compile(loss=self.critic_PPO2_loss, optimizer=optimizer(lr=lr))\n",
    "\n",
    "    def critic_PPO2_loss(self, y_true, y_pred):\n",
    "        value_loss = K.mean((y_true - y_pred) ** 2)\n",
    "        return value_loss\n",
    "\n",
    "    def critic_predict(self, state):\n",
    "        return self.Critic.predict([state, np.zeros((state.shape[0], 1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93f13f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4ef63a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import deque\n",
    "from tensorboardX import SummaryWriter\n",
    "from tensorflow.keras.optimizers.legacy import Adam, RMSprop\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "class CustomAgent:\n",
    "    def __init__(self, lookback_window_size=50, lr=0.00005, epochs=1, optimizer=Adam, batch_size=32, model=\"\"):\n",
    "        self.lookback_window_size = lookback_window_size\n",
    "        self.model = model\n",
    "        \n",
    "        self.action_space = np.array([0, 1, 2])\n",
    "\n",
    "        self.log_name = datetime.now().strftime(\"%Y_%m_%d_%H_%M\")+\"_trader\"\n",
    "        \n",
    "        self.state_size = (lookback_window_size, 15)\n",
    "\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "        self.optimizer = optimizer\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.Actor = Actor_Model(input_shape=self.state_size, action_space = self.action_space.shape[0], lr=self.lr, optimizer = self.optimizer)\n",
    "        self.Critic = Critic_Model(input_shape=self.state_size, action_space = self.action_space.shape[0], lr=self.lr, optimizer = self.optimizer)\n",
    "        \n",
    "    def create_writer(self, initial_balance, normalize_value, train_episodes):\n",
    "        self.replay_count = 0\n",
    "        self.writer = SummaryWriter('runs/'+self.log_name)\n",
    "\n",
    "        if not os.path.exists(self.log_name):\n",
    "            os.makedirs(self.log_name)\n",
    "\n",
    "        self.start_training_log(initial_balance, normalize_value, train_episodes)\n",
    "            \n",
    "    def start_training_log(self, initial_balance, normalize_value, train_episodes):\n",
    "        with open(self.log_name+\"/Parameters.txt\", \"w\") as params:\n",
    "            current_date = datetime.now().strftime('%Y-%m-%d %H:%M')\n",
    "            params.write(f\"training start: {current_date}\\n\")\n",
    "            params.write(f\"initial_balance: {initial_balance}\\n\")\n",
    "            params.write(f\"training episodes: {train_episodes}\\n\")\n",
    "            params.write(f\"lookback_window_size: {self.lookback_window_size}\\n\")\n",
    "            params.write(f\"lr: {self.lr}\\n\")\n",
    "            params.write(f\"epochs: {self.epochs}\\n\")\n",
    "            params.write(f\"batch size: {self.batch_size}\\n\")\n",
    "            params.write(f\"normalize_value: {normalize_value}\\n\")\n",
    "            params.write(f\"model: {self.model}\\n\")\n",
    "            \n",
    "    def end_training_log(self):\n",
    "        with open(self.log_name+\"/Parameters.txt\", \"a+\") as params:\n",
    "            current_date = datetime.now().strftime('%Y-%m-%d %H:%M')\n",
    "            params.write(f\"training end: {current_date}\\n\")\n",
    "\n",
    "    def get_gaes(self, rewards, dones, values, next_values, gamma = 0.99, lamda = 0.95, normalize=True):\n",
    "        deltas = [r + gamma * (1 - d) * nv - v for r, d, nv, v in zip(rewards, dones, next_values, values)]\n",
    "        deltas = np.stack(deltas)\n",
    "        gaes = copy.deepcopy(deltas)\n",
    "        for t in reversed(range(len(deltas) - 1)):\n",
    "            gaes[t] = gaes[t] + (1 - dones[t]) * gamma * lamda * gaes[t + 1]\n",
    "\n",
    "        target = gaes + values\n",
    "        if normalize:\n",
    "            gaes = (gaes - gaes.mean()) / (gaes.std() + 1e-8)\n",
    "        return np.vstack(gaes), np.vstack(target)\n",
    "\n",
    "    def replay(self, states, actions, rewards, predictions, dones, next_states):\n",
    "        states = np.vstack(states)\n",
    "        next_states = np.vstack(next_states)\n",
    "        actions = np.vstack(actions)\n",
    "        predictions = np.vstack(predictions)\n",
    "\n",
    "        values = self.Critic.critic_predict(states)\n",
    "        next_values = self.Critic.critic_predict(next_states)\n",
    "        \n",
    "        advantages, target = self.get_gaes(rewards, dones, np.squeeze(values), np.squeeze(next_values))\n",
    "        y_true = np.hstack([advantages, predictions, actions])\n",
    "        \n",
    "        a_loss = self.Actor.Actor.fit(states, y_true, epochs=self.epochs, verbose=0, shuffle=True, batch_size=self.batch_size)\n",
    "        c_loss = self.Critic.Critic.fit(states, target, epochs=self.epochs, verbose=0, shuffle=True, batch_size=self.batch_size)\n",
    "\n",
    "        self.writer.add_scalar('Data/actor_loss_per_replay', np.sum(a_loss.history['loss']), self.replay_count)\n",
    "        self.writer.add_scalar('Data/critic_loss_per_replay', np.sum(c_loss.history['loss']), self.replay_count)\n",
    "        self.replay_count += 1\n",
    "\n",
    "        return np.sum(a_loss.history['loss']), np.sum(c_loss.history['loss'])\n",
    "\n",
    "    def act(self, state):\n",
    "        prediction = self.Actor.actor_predict(np.expand_dims(state, axis=0))[0]\n",
    "        action = np.random.choice(self.action_space, p=prediction)\n",
    "        return action, prediction\n",
    "        \n",
    "    def save(self, name=\"trader\", score=\"\", args=[]):\n",
    "        self.Actor.Actor.save_weights(f\"{self.log_name}/{score}_{name}_Actor.h5\")\n",
    "        self.Critic.Critic.save_weights(f\"{self.log_name}/{score}_{name}_Critic.h5\")\n",
    "\n",
    "        if len(args) > 0:\n",
    "            with open(f\"{self.log_name}/log.txt\", \"a+\") as log:\n",
    "                current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "                atgumets = \"\"\n",
    "                for arg in args:\n",
    "                    atgumets += f\", {arg}\"\n",
    "                log.write(f\"{current_time}{atgumets}\\n\")\n",
    "\n",
    "    def load(self, folder, name):\n",
    "        self.Actor.Actor.load_weights(os.path.join(folder, f\"{name}_Actor.h5\"))\n",
    "        self.Critic.Critic.load_weights(os.path.join(folder, f\"{name}_Critic.h5\"))\n",
    "\n",
    "        \n",
    "class CustomEnv:\n",
    "    def __init__(self, df, initial_balance=1000, lookback_window_size=50, Render_range=100, Show_reward=False, Show_indicators=False, normalize_value=40000):\n",
    "        self.df = df.dropna().reset_index()\n",
    "        self.df_graph = df.dropna().reset_index()\n",
    "        self.df_total_steps = len(self.df)-1\n",
    "        self.initial_balance = initial_balance\n",
    "        self.lookback_window_size = lookback_window_size\n",
    "        self.Render_range = Render_range\n",
    "        self.Show_reward = Show_reward\n",
    "        self.Show_indicators = Show_indicators\n",
    "\n",
    "        self.orders_history = deque(maxlen=self.lookback_window_size)\n",
    "        \n",
    "        self.market_history = deque(maxlen=self.lookback_window_size)\n",
    "\n",
    "        self.indicators_history = deque(maxlen=self.lookback_window_size)\n",
    "\n",
    "        self.normalize_value = normalize_value\n",
    "\n",
    "    def reset(self, env_steps_size = 0):\n",
    "        self.visualization = TradingGraph(Render_range=self.Render_range, Show_reward=self.Show_reward, Show_indicators=self.Show_indicators) # init visualization\n",
    "        self.trades = deque(maxlen=self.Render_range)\n",
    "        \n",
    "        self.balance = self.initial_balance\n",
    "        self.net_worth = self.initial_balance\n",
    "        self.prev_net_worth = self.initial_balance\n",
    "        self.held = 0\n",
    "        self.sold = 0\n",
    "        self.bought = 0\n",
    "        self.episode_orders = 0\n",
    "        self.prev_episode_orders = 0\n",
    "        self.rewards = deque(maxlen=self.Render_range)\n",
    "        self.env_steps_size = env_steps_size\n",
    "        self.punish_value = 0\n",
    "        if env_steps_size > 0:\n",
    "            self.start_step = random.randint(self.lookback_window_size, self.df_total_steps - env_steps_size)\n",
    "            self.end_step = self.start_step + env_steps_size\n",
    "        else:\n",
    "            self.start_step = self.lookback_window_size\n",
    "            self.end_step = self.df_total_steps\n",
    "            \n",
    "        self.current_step = self.start_step\n",
    "\n",
    "        for i in reversed(range(self.lookback_window_size)):\n",
    "            current_step = self.current_step - i\n",
    "            self.orders_history.append([self.balance, self.net_worth, self.bought, self.sold, self.held])\n",
    "\n",
    "            self.market_history.append([self.df.loc[current_step, 'open'],\n",
    "                                        self.df.loc[current_step, 'high'],\n",
    "                                        self.df.loc[current_step, 'low'],\n",
    "                                        self.df.loc[current_step, 'close'],\n",
    "                                        self.df.loc[current_step, 'volume'],\n",
    "                                        ])\n",
    "\n",
    "            self.indicators_history.append([\n",
    "                                        self.df.loc[current_step, 'ema5'] / self.normalize_value,\n",
    "                                        self.df.loc[current_step, 'ema8'] / self.normalize_value,\n",
    "                                        self.df.loc[current_step, 'ema13'] / self.normalize_value,\n",
    "                                        self.df.loc[current_step, 'MACD'],\n",
    "                                        self.df.loc[current_step, 'RSI'] / 100\n",
    "                                        ])\n",
    "            \n",
    "\n",
    "        state = np.concatenate((self.market_history, self.orders_history), axis=1) / self.normalize_value\n",
    "        state = np.concatenate((state, self.indicators_history), axis=1)\n",
    "\n",
    "        return state\n",
    "\n",
    "    def _next_observation(self):\n",
    "        self.market_history.append([self.df.loc[self.current_step, 'open'],\n",
    "                                    self.df.loc[self.current_step, 'high'],\n",
    "                                    self.df.loc[self.current_step, 'low'],\n",
    "                                    self.df.loc[self.current_step, 'close'],\n",
    "                                    self.df.loc[self.current_step, 'volume'],\n",
    "                                    ])\n",
    "\n",
    "        self.indicators_history.append([self.df.loc[self.current_step, 'ema8'] / self.normalize_value,\n",
    "                                    self.df.loc[self.current_step, 'ema8'] / self.normalize_value,\n",
    "                                    self.df.loc[self.current_step, 'ema13'] / self.normalize_value,\n",
    "                                    self.df.loc[self.current_step, 'MACD'],\n",
    "                                    self.df.loc[self.current_step, 'RSI'] / 100\n",
    "                                    ])\n",
    "        \n",
    "        obs = np.concatenate((self.market_history, self.orders_history), axis=1) / self.normalize_value\n",
    "        obs = np.concatenate((obs, self.indicators_history), axis=1)\n",
    "        \n",
    "        return obs\n",
    "\n",
    "    def step(self, action):\n",
    "        self.bought = 0\n",
    "        self.sold = 0\n",
    "        self.current_step += 1\n",
    "\n",
    "        current_price = self.df.loc[self.current_step, 'open']\n",
    "        Date = self.df.loc[self.current_step, 'datetime']\n",
    "        High = self.df.loc[self.current_step, 'high']\n",
    "        Low = self.df.loc[self.current_step, 'low']\n",
    "\n",
    "        if action == 0:\n",
    "            pass\n",
    "\n",
    "        elif action == 1 and self.balance > self.initial_balance/100:\n",
    "            self.bought = self.balance / current_price\n",
    "            self.balance -= self.bought * current_price\n",
    "            self.held += self.bought\n",
    "            self.trades.append({'datetime' : Date, 'high' : High, 'low' : Low, 'total': self.bought, 'type': \"buy\", 'current_price': current_price})\n",
    "            self.episode_orders += 1\n",
    "\n",
    "        elif action == 2 and self.held>0:\n",
    "            self.sold = self.held\n",
    "            self.balance += self.sold * current_price\n",
    "            self.held -= self.sold\n",
    "            self.trades.append({'datetime' : Date, 'high' : High, 'low' : Low, 'total': self.sold, 'type': \"sell\", 'current_price': current_price})\n",
    "            self.episode_orders += 1\n",
    "\n",
    "        self.prev_net_worth = self.net_worth\n",
    "        self.net_worth = self.balance + self.held * current_price\n",
    "\n",
    "        self.orders_history.append([self.balance, self.net_worth, self.bought, self.sold, self.held])\n",
    "\n",
    "        reward = self.get_reward()\n",
    "\n",
    "        if self.net_worth <= self.initial_balance/2:\n",
    "            done = True\n",
    "        else:\n",
    "            done = False\n",
    "\n",
    "        obs = self._next_observation()\n",
    "        \n",
    "        return obs, reward, done\n",
    "\n",
    "    def get_reward(self):\n",
    "        self.punish_value += self.net_worth * 0.00001\n",
    "        if self.episode_orders > 1 and self.episode_orders > self.prev_episode_orders:\n",
    "            self.prev_episode_orders = self.episode_orders\n",
    "            if self.trades[-1]['type'] == \"buy\" and self.trades[-2]['type'] == \"sell\":\n",
    "                reward = self.trades[-2]['total']*self.trades[-2]['current_price'] - self.trades[-2]['total']*self.trades[-1]['current_price']\n",
    "                reward -= self.punish_value\n",
    "                self.punish_value = 0\n",
    "                self.trades[-1][\"Reward\"] = reward\n",
    "                return reward\n",
    "            elif self.trades[-1]['type'] == \"sell\" and self.trades[-2]['type'] == \"buy\":\n",
    "                reward = self.trades[-1]['total']*self.trades[-1]['current_price'] - self.trades[-2]['total']*self.trades[-2]['current_price']\n",
    "                reward -= self.punish_value\n",
    "                self.punish_value = 0\n",
    "                self.trades[-1][\"Reward\"] = reward\n",
    "                return reward\n",
    "        else:\n",
    "            return 0 - self.punish_value\n",
    "\n",
    "    def render(self, visualize = False):\n",
    "        if visualize:\n",
    "            img = self.visualization.render(self.df.loc[self.current_step], self.net_worth, self.trades)\n",
    "            return img\n",
    "\n",
    "def train_agent(env, agent, visualize=False, train_episodes = 50, training_batch_size=500):\n",
    "    agent.create_writer(env.initial_balance, env.normalize_value, train_episodes)\n",
    "    total_average = deque(maxlen=100)\n",
    "    best_average = 0\n",
    "    for episode in range(train_episodes):\n",
    "        state = env.reset(env_steps_size = training_batch_size)\n",
    "\n",
    "        states, actions, rewards, predictions, dones, next_states = [], [], [], [], [], []\n",
    "        for t in range(training_batch_size):\n",
    "            env.render(visualize)\n",
    "            action, prediction = agent.act(state)\n",
    "            next_state, reward, done = env.step(action)\n",
    "            states.append(np.expand_dims(state, axis=0))\n",
    "            next_states.append(np.expand_dims(next_state, axis=0))\n",
    "            action_onehot = np.zeros(3)\n",
    "            action_onehot[action] = 1\n",
    "            actions.append(action_onehot)\n",
    "            rewards.append(reward)\n",
    "            dones.append(done)\n",
    "            predictions.append(prediction)\n",
    "            state = next_state\n",
    "\n",
    "        a_loss, c_loss = agent.replay(states, actions, rewards, predictions, dones, next_states)\n",
    "        total_average.append(env.net_worth)\n",
    "        average = np.average(total_average)\n",
    "        \n",
    "        agent.writer.add_scalar('Data/average net_worth', average, episode)\n",
    "        agent.writer.add_scalar('Data/episode_orders', env.episode_orders, episode)\n",
    "        \n",
    "        print(\"episode: {:<5} net worth {:<7.2f} average: {:<7.2f} orders: {}\".format(episode, env.net_worth, average, env.episode_orders))\n",
    "        if episode > len(total_average):\n",
    "            if best_average < average:\n",
    "                best_average = average\n",
    "                print(\"Saving model\")\n",
    "                agent.save(score=\"{:.2f}\".format(best_average), args=[episode, average, env.episode_orders, a_loss, c_loss])\n",
    "            agent.save()\n",
    "            \n",
    "    agent.end_training_log()\n",
    "    \n",
    "def test_agent(env, agent, visualize=True, test_episodes=10, folder=\"\", name=\"_trader\", comment=\"\"):\n",
    "    agent.load(folder, name)\n",
    "    average_net_worth = 0\n",
    "    average_orders = 0\n",
    "    no_profit_episodes = 0\n",
    "    for episode in range(test_episodes):\n",
    "        state = env.reset()\n",
    "        while True:\n",
    "            env.render(visualize)\n",
    "            action, prediction = agent.act(state)\n",
    "            state, reward, done = env.step(action)\n",
    "            if env.current_step == env.end_step:\n",
    "                average_net_worth += env.net_worth\n",
    "                average_orders += env.episode_orders\n",
    "                if env.net_worth < env.initial_balance: no_profit_episodes += 1\n",
    "                print(\"episode: {:<5}, net_worth: {:<7.2f}, average_net_worth: {:<7.2f}, orders: {}\".format(episode, env.net_worth, average_net_worth/(episode+1), env.episode_orders))\n",
    "                break\n",
    "            \n",
    "    print(\"average {} episodes agent net_worth: {}, orders: {}\".format(test_episodes, average_net_worth/test_episodes, average_orders/test_episodes))\n",
    "    print(\"No profit episodes: {}\".format(no_profit_episodes))\n",
    "    with open(\"test_results.txt\", \"a+\") as results:\n",
    "        current_date = datetime.now().strftime('%Y-%m-%d %H:%M')\n",
    "        results.write(f'{current_date}, {name}, test episodes:{test_episodes}')\n",
    "        results.write(f', net worth:{average_net_worth/(episode+1)}, orders per episode:{average_orders/test_episodes}')\n",
    "        results.write(f', no profit episodes:{no_profit_episodes}, model: {agent.model}, comment: {comment}\\n')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d2a5480a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf = pd.read_csv('pfedata.csv')[['datetime','open','high','low','close','volume','ema5','ema8','ema13','MACD','RSI']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4e3b0223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>ema5</th>\n",
       "      <th>ema8</th>\n",
       "      <th>ema13</th>\n",
       "      <th>MACD</th>\n",
       "      <th>RSI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-02 17:30:00</td>\n",
       "      <td>37.235397</td>\n",
       "      <td>37.292274</td>\n",
       "      <td>36.875177</td>\n",
       "      <td>36.988931</td>\n",
       "      <td>264176.0</td>\n",
       "      <td>36.988931</td>\n",
       "      <td>36.988931</td>\n",
       "      <td>36.988931</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-02 18:30:00</td>\n",
       "      <td>36.988931</td>\n",
       "      <td>37.050548</td>\n",
       "      <td>36.894136</td>\n",
       "      <td>36.936794</td>\n",
       "      <td>113237.0</td>\n",
       "      <td>36.971552</td>\n",
       "      <td>36.977345</td>\n",
       "      <td>36.981483</td>\n",
       "      <td>-0.004159</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-02 19:30:00</td>\n",
       "      <td>36.932054</td>\n",
       "      <td>36.951013</td>\n",
       "      <td>36.894136</td>\n",
       "      <td>36.946273</td>\n",
       "      <td>75932.0</td>\n",
       "      <td>36.963126</td>\n",
       "      <td>36.970440</td>\n",
       "      <td>36.976453</td>\n",
       "      <td>-0.006614</td>\n",
       "      <td>16.373612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-02 20:30:00</td>\n",
       "      <td>36.946273</td>\n",
       "      <td>36.951013</td>\n",
       "      <td>36.884657</td>\n",
       "      <td>36.894136</td>\n",
       "      <td>48912.0</td>\n",
       "      <td>36.940129</td>\n",
       "      <td>36.953484</td>\n",
       "      <td>36.964693</td>\n",
       "      <td>-0.012621</td>\n",
       "      <td>8.312035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-02 21:30:00</td>\n",
       "      <td>36.903616</td>\n",
       "      <td>36.913095</td>\n",
       "      <td>36.860958</td>\n",
       "      <td>36.879917</td>\n",
       "      <td>55462.0</td>\n",
       "      <td>36.920058</td>\n",
       "      <td>36.937135</td>\n",
       "      <td>36.952582</td>\n",
       "      <td>-0.018318</td>\n",
       "      <td>7.261924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5850</th>\n",
       "      <td>2023-04-28 20:30:00</td>\n",
       "      <td>38.865000</td>\n",
       "      <td>38.880000</td>\n",
       "      <td>38.700000</td>\n",
       "      <td>38.770000</td>\n",
       "      <td>302146.0</td>\n",
       "      <td>38.773945</td>\n",
       "      <td>38.743905</td>\n",
       "      <td>38.747369</td>\n",
       "      <td>-0.194387</td>\n",
       "      <td>43.459267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5851</th>\n",
       "      <td>2023-04-28 21:30:00</td>\n",
       "      <td>38.770000</td>\n",
       "      <td>38.800000</td>\n",
       "      <td>38.705000</td>\n",
       "      <td>38.760000</td>\n",
       "      <td>212364.0</td>\n",
       "      <td>38.769297</td>\n",
       "      <td>38.747481</td>\n",
       "      <td>38.749173</td>\n",
       "      <td>-0.178510</td>\n",
       "      <td>43.152600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5852</th>\n",
       "      <td>2023-04-28 22:30:00</td>\n",
       "      <td>38.760000</td>\n",
       "      <td>38.910000</td>\n",
       "      <td>38.710000</td>\n",
       "      <td>38.900000</td>\n",
       "      <td>492133.0</td>\n",
       "      <td>38.812865</td>\n",
       "      <td>38.781374</td>\n",
       "      <td>38.770720</td>\n",
       "      <td>-0.152869</td>\n",
       "      <td>48.618985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5853</th>\n",
       "      <td>2023-05-01 16:30:00</td>\n",
       "      <td>39.010000</td>\n",
       "      <td>39.200000</td>\n",
       "      <td>38.870000</td>\n",
       "      <td>39.140000</td>\n",
       "      <td>496579.0</td>\n",
       "      <td>38.921910</td>\n",
       "      <td>38.861069</td>\n",
       "      <td>38.823474</td>\n",
       "      <td>-0.111892</td>\n",
       "      <td>56.365215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5854</th>\n",
       "      <td>2023-05-01 17:30:00</td>\n",
       "      <td>39.135000</td>\n",
       "      <td>39.285000</td>\n",
       "      <td>39.135000</td>\n",
       "      <td>39.180000</td>\n",
       "      <td>243242.0</td>\n",
       "      <td>39.007940</td>\n",
       "      <td>38.931943</td>\n",
       "      <td>38.874406</td>\n",
       "      <td>-0.075321</td>\n",
       "      <td>57.514846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5855 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 datetime       open       high        low      close  \\\n",
       "0     2020-01-02 17:30:00  37.235397  37.292274  36.875177  36.988931   \n",
       "1     2020-01-02 18:30:00  36.988931  37.050548  36.894136  36.936794   \n",
       "2     2020-01-02 19:30:00  36.932054  36.951013  36.894136  36.946273   \n",
       "3     2020-01-02 20:30:00  36.946273  36.951013  36.884657  36.894136   \n",
       "4     2020-01-02 21:30:00  36.903616  36.913095  36.860958  36.879917   \n",
       "...                   ...        ...        ...        ...        ...   \n",
       "5850  2023-04-28 20:30:00  38.865000  38.880000  38.700000  38.770000   \n",
       "5851  2023-04-28 21:30:00  38.770000  38.800000  38.705000  38.760000   \n",
       "5852  2023-04-28 22:30:00  38.760000  38.910000  38.710000  38.900000   \n",
       "5853  2023-05-01 16:30:00  39.010000  39.200000  38.870000  39.140000   \n",
       "5854  2023-05-01 17:30:00  39.135000  39.285000  39.135000  39.180000   \n",
       "\n",
       "        volume       ema5       ema8      ema13      MACD         RSI  \n",
       "0     264176.0  36.988931  36.988931  36.988931  0.000000  100.000000  \n",
       "1     113237.0  36.971552  36.977345  36.981483 -0.004159    0.000000  \n",
       "2      75932.0  36.963126  36.970440  36.976453 -0.006614   16.373612  \n",
       "3      48912.0  36.940129  36.953484  36.964693 -0.012621    8.312035  \n",
       "4      55462.0  36.920058  36.937135  36.952582 -0.018318    7.261924  \n",
       "...        ...        ...        ...        ...       ...         ...  \n",
       "5850  302146.0  38.773945  38.743905  38.747369 -0.194387   43.459267  \n",
       "5851  212364.0  38.769297  38.747481  38.749173 -0.178510   43.152600  \n",
       "5852  492133.0  38.812865  38.781374  38.770720 -0.152869   48.618985  \n",
       "5853  496579.0  38.921910  38.861069  38.823474 -0.111892   56.365215  \n",
       "5854  243242.0  39.007940  38.931943  38.874406 -0.075321   57.514846  \n",
       "\n",
       "[5855 rows x 11 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6390add0",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f1bf901",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50337204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 8088 (pid 14256), started 1 day, 3:46:05 ago. (Use '!kill 14256' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-dcfdc3e84ef48ab1\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-dcfdc3e84ef48ab1\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 8088;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tensorboard --logdir=runs/ --host localhost --port 8088"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "919b05f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ThinkPadX4\\anaconda3\\lib\\site-packages\\keras\\optimizers\\legacy\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "lookback_window_size = 50\n",
    "test_window = 805\n",
    "train_df = ddf[:-test_window-lookback_window_size]\n",
    "test_df = ddf[-test_window-lookback_window_size:]\n",
    "agent = CustomAgent(lookback_window_size=lookback_window_size, lr=0.00001, epochs=5, optimizer=Adam, batch_size = 32, model=\"Dense\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c19ae74f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ThinkPadX4\\AppData\\Local\\Temp\\ipykernel_7516\\1364660045.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['datetime'] = pd.date_range(start = \"2022-11-21 18:30:00\", periods = 855, freq='H')\n"
     ]
    }
   ],
   "source": [
    "test_df['datetime'] = pd.date_range(start = \"2022-11-21 18:30:00\", periods = 855, freq='H')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3173758d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df.iloc[:350]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d3af60e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>ema5</th>\n",
       "      <th>ema8</th>\n",
       "      <th>ema13</th>\n",
       "      <th>MACD</th>\n",
       "      <th>RSI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5000</th>\n",
       "      <td>2022-11-21 18:30:00</td>\n",
       "      <td>48.010</td>\n",
       "      <td>48.080</td>\n",
       "      <td>47.855</td>\n",
       "      <td>48.010</td>\n",
       "      <td>164095.0</td>\n",
       "      <td>47.874715</td>\n",
       "      <td>47.732564</td>\n",
       "      <td>47.535662</td>\n",
       "      <td>0.456151</td>\n",
       "      <td>67.239274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5001</th>\n",
       "      <td>2022-11-21 19:30:00</td>\n",
       "      <td>47.810</td>\n",
       "      <td>48.090</td>\n",
       "      <td>47.220</td>\n",
       "      <td>47.310</td>\n",
       "      <td>173494.0</td>\n",
       "      <td>47.686477</td>\n",
       "      <td>47.638661</td>\n",
       "      <td>47.503425</td>\n",
       "      <td>0.401467</td>\n",
       "      <td>53.323618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5002</th>\n",
       "      <td>2022-11-21 20:30:00</td>\n",
       "      <td>47.320</td>\n",
       "      <td>47.445</td>\n",
       "      <td>47.195</td>\n",
       "      <td>47.350</td>\n",
       "      <td>95036.0</td>\n",
       "      <td>47.574318</td>\n",
       "      <td>47.574514</td>\n",
       "      <td>47.481507</td>\n",
       "      <td>0.357240</td>\n",
       "      <td>53.910604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5003</th>\n",
       "      <td>2022-11-21 21:30:00</td>\n",
       "      <td>47.340</td>\n",
       "      <td>47.410</td>\n",
       "      <td>47.045</td>\n",
       "      <td>47.045</td>\n",
       "      <td>50356.0</td>\n",
       "      <td>47.397878</td>\n",
       "      <td>47.456844</td>\n",
       "      <td>47.419149</td>\n",
       "      <td>0.294187</td>\n",
       "      <td>48.864575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5004</th>\n",
       "      <td>2022-11-21 22:30:00</td>\n",
       "      <td>47.045</td>\n",
       "      <td>47.270</td>\n",
       "      <td>46.960</td>\n",
       "      <td>47.230</td>\n",
       "      <td>75199.0</td>\n",
       "      <td>47.341919</td>\n",
       "      <td>47.406434</td>\n",
       "      <td>47.392127</td>\n",
       "      <td>0.256192</td>\n",
       "      <td>51.810902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5345</th>\n",
       "      <td>2022-12-06 03:30:00</td>\n",
       "      <td>48.010</td>\n",
       "      <td>48.010</td>\n",
       "      <td>47.860</td>\n",
       "      <td>47.910</td>\n",
       "      <td>44387.0</td>\n",
       "      <td>47.869966</td>\n",
       "      <td>47.782080</td>\n",
       "      <td>47.717245</td>\n",
       "      <td>-0.193203</td>\n",
       "      <td>49.365265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5346</th>\n",
       "      <td>2022-12-06 04:30:00</td>\n",
       "      <td>47.910</td>\n",
       "      <td>48.025</td>\n",
       "      <td>47.850</td>\n",
       "      <td>47.890</td>\n",
       "      <td>47858.0</td>\n",
       "      <td>47.876644</td>\n",
       "      <td>47.806062</td>\n",
       "      <td>47.741924</td>\n",
       "      <td>-0.165421</td>\n",
       "      <td>48.941638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5347</th>\n",
       "      <td>2022-12-06 05:30:00</td>\n",
       "      <td>47.885</td>\n",
       "      <td>48.020</td>\n",
       "      <td>47.800</td>\n",
       "      <td>47.870</td>\n",
       "      <td>127696.0</td>\n",
       "      <td>47.874430</td>\n",
       "      <td>47.820270</td>\n",
       "      <td>47.760221</td>\n",
       "      <td>-0.143365</td>\n",
       "      <td>48.493482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5348</th>\n",
       "      <td>2022-12-06 06:30:00</td>\n",
       "      <td>47.865</td>\n",
       "      <td>47.980</td>\n",
       "      <td>47.805</td>\n",
       "      <td>47.850</td>\n",
       "      <td>95091.0</td>\n",
       "      <td>47.866286</td>\n",
       "      <td>47.826877</td>\n",
       "      <td>47.773046</td>\n",
       "      <td>-0.126046</td>\n",
       "      <td>48.019941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5349</th>\n",
       "      <td>2022-12-06 07:30:00</td>\n",
       "      <td>46.520</td>\n",
       "      <td>46.730</td>\n",
       "      <td>45.725</td>\n",
       "      <td>46.550</td>\n",
       "      <td>363827.0</td>\n",
       "      <td>47.427524</td>\n",
       "      <td>47.543126</td>\n",
       "      <td>47.598325</td>\n",
       "      <td>-0.214744</td>\n",
       "      <td>28.522971</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>350 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                datetime    open    high     low   close    volume       ema5  \\\n",
       "5000 2022-11-21 18:30:00  48.010  48.080  47.855  48.010  164095.0  47.874715   \n",
       "5001 2022-11-21 19:30:00  47.810  48.090  47.220  47.310  173494.0  47.686477   \n",
       "5002 2022-11-21 20:30:00  47.320  47.445  47.195  47.350   95036.0  47.574318   \n",
       "5003 2022-11-21 21:30:00  47.340  47.410  47.045  47.045   50356.0  47.397878   \n",
       "5004 2022-11-21 22:30:00  47.045  47.270  46.960  47.230   75199.0  47.341919   \n",
       "...                  ...     ...     ...     ...     ...       ...        ...   \n",
       "5345 2022-12-06 03:30:00  48.010  48.010  47.860  47.910   44387.0  47.869966   \n",
       "5346 2022-12-06 04:30:00  47.910  48.025  47.850  47.890   47858.0  47.876644   \n",
       "5347 2022-12-06 05:30:00  47.885  48.020  47.800  47.870  127696.0  47.874430   \n",
       "5348 2022-12-06 06:30:00  47.865  47.980  47.805  47.850   95091.0  47.866286   \n",
       "5349 2022-12-06 07:30:00  46.520  46.730  45.725  46.550  363827.0  47.427524   \n",
       "\n",
       "           ema8      ema13      MACD        RSI  \n",
       "5000  47.732564  47.535662  0.456151  67.239274  \n",
       "5001  47.638661  47.503425  0.401467  53.323618  \n",
       "5002  47.574514  47.481507  0.357240  53.910604  \n",
       "5003  47.456844  47.419149  0.294187  48.864575  \n",
       "5004  47.406434  47.392127  0.256192  51.810902  \n",
       "...         ...        ...       ...        ...  \n",
       "5345  47.782080  47.717245 -0.193203  49.365265  \n",
       "5346  47.806062  47.741924 -0.165421  48.941638  \n",
       "5347  47.820270  47.760221 -0.143365  48.493482  \n",
       "5348  47.826877  47.773046 -0.126046  48.019941  \n",
       "5349  47.543126  47.598325 -0.214744  28.522971  \n",
       "\n",
       "[350 rows x 11 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bcd254",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194f88bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d8891717",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ThinkPadX4\\anaconda3\\lib\\site-packages\\keras\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 0     net worth 955.37  average: 955.37  orders: 38\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m train_env \u001b[38;5;241m=\u001b[39m CustomEnv(train_df, lookback_window_size\u001b[38;5;241m=\u001b[39mlookback_window_size)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtrain_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_env\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_episodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36mtrain_agent\u001b[1;34m(env, agent, visualize, train_episodes, training_batch_size)\u001b[0m\n\u001b[0;32m    341\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(training_batch_size):\n\u001b[0;32m    342\u001b[0m     env\u001b[38;5;241m.\u001b[39mrender(visualize)\n\u001b[1;32m--> 343\u001b[0m     action, prediction \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mact\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    344\u001b[0m     next_state, reward, done \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[0;32m    345\u001b[0m     states\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mexpand_dims(state, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m))\n",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36mCustomAgent.act\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mact\u001b[39m(\u001b[38;5;28mself\u001b[39m, state):\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;66;03m# Use the network to predict the next action to take, using the model\u001b[39;00m\n\u001b[1;32m--> 111\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mActor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactor_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand_dims\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    112\u001b[0m     action \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space, p\u001b[38;5;241m=\u001b[39mprediction)\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m action, prediction\n",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36mShared_Model.actor_predict\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mactor_predict\u001b[39m(\u001b[38;5;28mself\u001b[39m, state):\n\u001b[1;32m---> 68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mActor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training_v1.py:1059\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1056\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_call_args(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1058\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_training_loop(x)\n\u001b[1;32m-> 1059\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1060\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1061\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1062\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1063\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1064\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1065\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1066\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1067\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1068\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1069\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays_v1.py:801\u001b[0m, in \u001b[0;36mArrayLikeTrainingLoop.predict\u001b[1;34m(self, model, x, batch_size, verbose, steps, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    797\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39m_validate_or_infer_batch_size(batch_size, steps, x)\n\u001b[0;32m    798\u001b[0m x, _, _ \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39m_standardize_user_data(\n\u001b[0;32m    799\u001b[0m     x, check_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, steps_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msteps\u001b[39m\u001b[38;5;124m\"\u001b[39m, steps\u001b[38;5;241m=\u001b[39msteps\n\u001b[0;32m    800\u001b[0m )\n\u001b[1;32m--> 801\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpredict_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    802\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    803\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    804\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    805\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    806\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    807\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    808\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays_v1.py:421\u001b[0m, in \u001b[0;36mmodel_iteration\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    416\u001b[0m callbacks\u001b[38;5;241m.\u001b[39m_call_batch_hook(\n\u001b[0;32m    417\u001b[0m     mode, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbegin\u001b[39m\u001b[38;5;124m\"\u001b[39m, batch_index, batch_logs\n\u001b[0;32m    418\u001b[0m )\n\u001b[0;32m    420\u001b[0m \u001b[38;5;66;03m# Get outputs.\u001b[39;00m\n\u001b[1;32m--> 421\u001b[0m batch_outs \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mins_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(batch_outs, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m    423\u001b[0m     batch_outs \u001b[38;5;241m=\u001b[39m [batch_outs]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\backend.py:4608\u001b[0m, in \u001b[0;36mGraphExecutionFunction.__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   4598\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   4599\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callable_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   4600\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m feed_arrays \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_feed_arrays\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4604\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m session \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_session\n\u001b[0;32m   4605\u001b[0m ):\n\u001b[0;32m   4606\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_callable(feed_arrays, feed_symbols, symbol_vals, session)\n\u001b[1;32m-> 4608\u001b[0m fetched \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_callable_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marray_vals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4609\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_fetch_callbacks(fetched[\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fetches) :])\n\u001b[0;32m   4610\u001b[0m output_structure \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mpack_sequence_as(\n\u001b[0;32m   4611\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_outputs_structure,\n\u001b[0;32m   4612\u001b[0m     fetched[: \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutputs)],\n\u001b[0;32m   4613\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   4614\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1481\u001b[0m, in \u001b[0;36mBaseSession._Callable.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1479\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1480\u001b[0m   run_metadata_ptr \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_NewBuffer() \u001b[38;5;28;01mif\u001b[39;00m run_metadata \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1481\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mtf_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTF_SessionRunCallable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1482\u001b[0m \u001b[43m                                         \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1483\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mrun_metadata_ptr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1484\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m run_metadata:\n\u001b[0;32m   1485\u001b[0m     proto_data \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_GetBuffer(run_metadata_ptr)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_env = CustomEnv(train_df, lookback_window_size=lookback_window_size)\n",
    "train_agent(train_env, agent, visualize=False, train_episodes=20000, training_batch_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6b55e4f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 0    , net_worth: 947.97 , average_net_worth: 947.97 , orders: 122\n",
      "episode: 1    , net_worth: 977.68 , average_net_worth: 962.83 , orders: 134\n",
      "episode: 2    , net_worth: 970.04 , average_net_worth: 965.23 , orders: 126\n",
      "episode: 3    , net_worth: 1003.72, average_net_worth: 974.85 , orders: 132\n",
      "episode: 4    , net_worth: 1005.36, average_net_worth: 980.95 , orders: 138\n",
      "episode: 5    , net_worth: 973.49 , average_net_worth: 979.71 , orders: 120\n",
      "episode: 6    , net_worth: 982.32 , average_net_worth: 980.08 , orders: 130\n",
      "episode: 7    , net_worth: 981.47 , average_net_worth: 980.26 , orders: 124\n",
      "episode: 8    , net_worth: 1045.49, average_net_worth: 987.50 , orders: 126\n",
      "episode: 9    , net_worth: 990.53 , average_net_worth: 987.81 , orders: 126\n",
      "episode: 10   , net_worth: 988.05 , average_net_worth: 987.83 , orders: 138\n",
      "episode: 11   , net_worth: 990.53 , average_net_worth: 988.05 , orders: 140\n",
      "episode: 12   , net_worth: 973.42 , average_net_worth: 986.93 , orders: 126\n",
      "episode: 13   , net_worth: 934.61 , average_net_worth: 983.19 , orders: 118\n",
      "episode: 14   , net_worth: 991.96 , average_net_worth: 983.78 , orders: 140\n",
      "episode: 15   , net_worth: 1009.22, average_net_worth: 985.37 , orders: 142\n",
      "episode: 16   , net_worth: 972.60 , average_net_worth: 984.62 , orders: 118\n",
      "episode: 17   , net_worth: 971.08 , average_net_worth: 983.86 , orders: 132\n",
      "episode: 18   , net_worth: 998.66 , average_net_worth: 984.64 , orders: 144\n",
      "episode: 19   , net_worth: 984.68 , average_net_worth: 984.64 , orders: 138\n",
      "episode: 20   , net_worth: 949.98 , average_net_worth: 982.99 , orders: 130\n",
      "episode: 21   , net_worth: 999.39 , average_net_worth: 983.74 , orders: 138\n",
      "episode: 22   , net_worth: 1002.75, average_net_worth: 984.57 , orders: 132\n",
      "episode: 23   , net_worth: 975.89 , average_net_worth: 984.20 , orders: 118\n",
      "episode: 24   , net_worth: 1008.22, average_net_worth: 985.16 , orders: 122\n",
      "episode: 25   , net_worth: 971.66 , average_net_worth: 984.65 , orders: 126\n",
      "episode: 26   , net_worth: 980.81 , average_net_worth: 984.50 , orders: 132\n",
      "episode: 27   , net_worth: 1023.59, average_net_worth: 985.90 , orders: 134\n",
      "episode: 28   , net_worth: 966.36 , average_net_worth: 985.23 , orders: 132\n",
      "episode: 29   , net_worth: 1019.29, average_net_worth: 986.36 , orders: 122\n",
      "episode: 30   , net_worth: 1004.57, average_net_worth: 986.95 , orders: 132\n",
      "episode: 31   , net_worth: 1002.19, average_net_worth: 987.42 , orders: 136\n",
      "episode: 32   , net_worth: 956.62 , average_net_worth: 986.49 , orders: 136\n",
      "episode: 33   , net_worth: 1022.39, average_net_worth: 987.55 , orders: 128\n",
      "episode: 34   , net_worth: 989.65 , average_net_worth: 987.61 , orders: 130\n",
      "episode: 35   , net_worth: 969.30 , average_net_worth: 987.10 , orders: 128\n",
      "episode: 36   , net_worth: 992.46 , average_net_worth: 987.24 , orders: 132\n",
      "episode: 37   , net_worth: 982.51 , average_net_worth: 987.12 , orders: 124\n",
      "episode: 38   , net_worth: 1028.30, average_net_worth: 988.17 , orders: 132\n",
      "episode: 39   , net_worth: 983.99 , average_net_worth: 988.07 , orders: 130\n",
      "episode: 40   , net_worth: 951.15 , average_net_worth: 987.17 , orders: 130\n",
      "episode: 41   , net_worth: 998.28 , average_net_worth: 987.43 , orders: 132\n",
      "episode: 42   , net_worth: 975.70 , average_net_worth: 987.16 , orders: 118\n",
      "episode: 43   , net_worth: 966.51 , average_net_worth: 986.69 , orders: 120\n",
      "episode: 44   , net_worth: 1003.03, average_net_worth: 987.05 , orders: 122\n",
      "episode: 45   , net_worth: 990.94 , average_net_worth: 987.14 , orders: 136\n",
      "episode: 46   , net_worth: 994.16 , average_net_worth: 987.29 , orders: 118\n",
      "episode: 47   , net_worth: 967.34 , average_net_worth: 986.87 , orders: 134\n",
      "episode: 48   , net_worth: 1001.15, average_net_worth: 987.16 , orders: 126\n",
      "episode: 49   , net_worth: 1005.19, average_net_worth: 987.52 , orders: 132\n",
      "average 50 episodes agent net_worth: 987.5246949320987, orders: 129.52\n",
      "No profit episodes: 35\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_env = CustomEnv(test_df, lookback_window_size=lookback_window_size, Show_reward=True, Show_indicators=True)\n",
    "test_agent(test_env, agent, visualize=False, test_episodes=50, folder=\"Big\", name=\"2635.74_trader\", comment=\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
